% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/desurv_cv_bayesopt.R
\name{desurv_cv_bayesopt}
\alias{desurv_cv_bayesopt}
\title{Bayesian optimisation of DeSurv CV hyperparameters}
\usage{
desurv_cv_bayesopt(
  X,
  y,
  d,
  dataset = NULL,
  samp_keeps = NULL,
  preprocess = TRUE,
  method_trans_train = c("rank", "quant", "none"),
  engine = c("cold", "warmstart"),
  nfolds = 5,
  tol = 1e-04,
  maxit = 100,
  bo_bounds = desurv_cv_bo_default_bounds(),
  n_init = NULL,
  n_iter = 20,
  candidate_pool = NULL,
  exploration_weight = 0,
  seed = NULL,
  cv_verbose = FALSE,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{X, y, d, dataset, samp_keeps}{Inputs forwarded to \code{\link[=desurv_cv]{desurv_cv()}}. Provide
\code{dataset}/\code{samp_keeps} when preprocessing is enabled.}

\item{preprocess, method_trans_train, engine}{Arguments passed through to
\code{\link[=desurv_cv]{desurv_cv()}}. Bayesian optimisation assumes the output metric is
comparable across iterations, so keep these unchanged throughout the run.}

\item{nfolds, tol, maxit}{Fixed CV/optimization parameters passed to
\code{\link[=desurv_cv]{desurv_cv()}}. These can also be tuned via \code{bo_bounds} if desired, but
typically you want to fix them for computational efficiency.}

\item{bo_bounds}{Named list describing the search space for hyperparameters
to tune. Each entry must be either a numeric vector of length two
(\code{c(lower, upper)}) or a list with elements \code{lower}, \code{upper}, and
optional \code{type = "continuous"}/\code{"integer"} plus
\code{scale = "linear"}/\code{"log10"}. See \code{\link[=desurv_cv_bo_default_bounds]{desurv_cv_bo_default_bounds()}} for
recommended ranges.}

\item{n_init}{Number of Latin-hypercube evaluations before fitting the GP.
Defaults to \code{max(5, 3 * length(bo_bounds))}.}

\item{n_iter}{Number of sequential BO iterations after the initial design.}

\item{candidate_pool}{Number of random candidates assessed per acquisition
step. Defaults to \code{max(1000, 200 * length(bo_bounds))}.}

\item{exploration_weight}{Non-negative scalar \code{xi} used in the expected
improvement formula to encourage exploration.}

\item{seed}{Optional base seed for reproducibility.}

\item{cv_verbose}{Logical; if \code{TRUE}, propagate \code{verbose = TRUE} into
\code{desurv_cv()} calls. The optimiser itself still reports progress via
\code{verbose}.}

\item{verbose}{Logical; print progress after each evaluation/iteration.}

\item{...}{Additional arguments forwarded to \code{\link[=desurv_cv]{desurv_cv()}} (for example
\code{folds}, \code{parallel_grid}, \code{ncores_grid}).}
}
\value{
An object of class \code{desurv_cv_bo} containing:
\itemize{
\item \code{history}: data frame of every evaluation (parameters, score, status).
\item \code{best}: list with \code{params} (named numeric vector) and
\code{mean_cindex}.
\item \code{bounds}: parsed search-space specification.
\item \code{fixed}: fixed hyperparameters (nfolds, tol, maxit).
\item \code{seed}: RNG seed used internally.
\item \code{call}: original function call.
}
}
\description{
Sequentially tunes hyperparameters for \code{\link[=desurv_cv]{desurv_cv()}} using Bayesian
optimization with a Gaussian process surrogate and expected-improvement
acquisition rule. Unlike grid search which evaluates all combinations,
this function efficiently explores the hyperparameter space by calling
\code{desurv_cv()} with single parameter values (not grids) and maximizing
the resulting mean validation C-index.
}
\details{
This function optimizes hyperparameters like \code{k}, \code{alpha}, \code{lambda}, \code{nu},
\code{lambdaW}, \code{lambdaH}, \code{n_starts}, and \code{ngene} by calling \code{desurv_cv()}
with single values (not grids) for each parameter. Each BO evaluation runs
cross-validation and extracts the mean C-index across folds.

The helper relies on the \code{DiceKriging} and \code{lhs} packages for Gaussian
process modelling and Latin hypercube sampling. They are listed under
\code{Suggests}; an informative error is thrown if they are not installed.

\strong{Important}: The parameter names in \code{bo_bounds} should match the
arguments to \code{desurv_cv()} (e.g., \code{k_grid}, \code{alpha_grid}, etc.) even
though you're passing single values. The function will extract these
and pass them as scalars.
}
\examples{
\dontrun{
data <- readRDS("data.rds")
bo_result <- desurv_cv_bayesopt(
  X = data$ex,
  y = data$sampInfo$time,
  d = data$sampInfo$event,
  dataset = data$sampInfo$dataset,
  samp_keeps = data$samp_keeps,
  preprocess = TRUE,
  method_trans_train = "rank",
  engine = "cold",
  nfolds = 5,
  tol = 1e-4,
  maxit = 100,
  bo_bounds = desurv_cv_bo_default_bounds(),
  n_init = 15,
  n_iter = 20,
  exploration_weight = 0.01,
  seed = 2025,
  verbose = TRUE
)
print(bo_result)

# Extract best parameters
best_params <- bo_result$best$params

# Refit with best parameters on full data
final_cv <- desurv_cv(
  X = data$ex,
  y = data$sampInfo$time,
  d = data$sampInfo$event,
  dataset = data$sampInfo$dataset,
  samp_keeps = data$samp_keeps,
  preprocess = TRUE,
  method_trans_train = "rank",
  k_grid = best_params["k_grid"],
  alpha_grid = best_params["alpha_grid"],
  lambda_grid = best_params["lambda_grid"],
  nu_grid = best_params["nu_grid"],
  lambdaW_grid = best_params["lambdaW_grid"],
  lambdaH_grid = best_params["lambdaH_grid"],
  n_starts = best_params["n_starts"],
  ngene = best_params["ngene"],
  nfolds = 5,
  tol = 1e-4,
  maxit = 100,
  engine = "cold"
)
}

}
\seealso{
\code{\link[=desurv_cv]{desurv_cv()}}, \code{\link[=desurv_cv_bo_default_bounds]{desurv_cv_bo_default_bounds()}}
}
